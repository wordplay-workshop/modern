---
layout: home
header:
  title: "Wordplay: When Language Meets Games
          @ ICML 2023"
  text: >
    Your one stop shop for all things interactive narrative + AI!

  action: # action button is optional
    label: Back to the '80s
    url: https://wordplay-workshop.github.io/


sections:
  - type: paragraph.html
    section_id: overview
    title: Overview
    text: >+

      **Date and time**: TBD <br />

      **Location**: TBD

      **Virtual links**: TBD <br />

      This workshop focused on exploring the utility of interactive narratives, think everything from classic text-adventures like [Zork](http://textadventures.online/play/?story=http%3A%2F%2Fwww.ifarchive.org%2Fif-archive%2Fgames%2Fhugo%2Fhugozork.hex) to modern [Twine](https://twinery.org/) games, to fill a role as the learning environments of choice for language-based tasks including but not limited to storytelling. A few previous iterations of this workshop took place very successfully with hundreds of attendees, at NeurIPS 2018 and NeurIPS 2020. Since then, the community of people working in this area has rapidly increased. This workshop aims to be a centralized place where all researchers involved across a breadth of fields can interact and learn from each other. Furthermore, it will act as a showcase to the wider NLP/RL/Game communities on interactive narrative's place as a learning environment. The program will feature a collection of invited talks in addition to contributed talks and posters from each of these sections of the interactive narrative community and the wider NLP and RL communities.  <br />

      We like all things:

      * Interactive narrative: game playing RL agents, game generation, etc.

      * Interactive language learning

      * Natural language generation

      * Improvisational storytelling

      * And more! Anything you can think of that involves narrative, interactivity, and language!

      <br />

      [Check out the full version of our overview!](/modern/full_overview)

  - type: paragraph.html
    section_id: cfp
    title: Call For Papers
    background_style: bg-lightdark
    text: >+

      **Submission website:** [OpenReview](https://openreview.net/group?id=aclweb.org/ICML/2023/Workshop/Wordplay).

      **Submission deadline:** TBD

      **Author notification:** TBD

      We welcome original research papers ranging between **4-8** pages in length (not including references or supplementary materials), formatted according to [the ICML 2023 style](https://icml.cc/Conferences/2023/StyleAuthorInstructions). Submissions should be in **.pdf** format. Since the review process is **double-blind**, all papers should be appropriately anonymised. Authors have the option of including supplementary manuscript containing further details of their work into **the same .pdf file**, it is entirely up to the reviewers to decide whether they wish to consult this additional material. Authors are strongly encouraged to make data and code publicly available whenever possible. The accepted papers will be posted on the workshop website and will not appear in the ICML proceedings.<br/>

      In addition, we welcome extended abstracts of up to 2 pages that describe open problems and challenges in this area.
      The papers will be non-archival, we welcome papers that have been published or submitted to other places.
      However, authors are required to acknowledge their papers' original appearance in such cases. <br/>

      All accepted papers and extended abstracts will be presented as posters.
      The program committee will select a few papers for oral presentation.

  # - type: schedule.html
  #   section_id: schedule
  #   title: Schedule - Thursday, July 14<sup>th</sup> (Pacific Time) - <a href="https://www.youtube.com/watch?v=XIQgB_MerAw">Live Session Recording</a>
  #   background_style: bg-lightdark
  #   events:
  #     - time: 09:00&nbsp;&ndash;&nbsp;09:10
  #       title: "Opening Remarks"
  #     - time: 09:10&nbsp;&ndash;&nbsp;09:55
  #       title: "Text Toys and Glitch Poetics \n **Lynn Cherny** [[link]](https://www.youtube.com/watch?v=XIQgB_MerAw&t=0)"
  #       abstract: >+
  #         Not just a bug, the glitch offers creative possibility -- especially in AI systems where we are travelers in a foggy latent space.  The glitch is usually a visual metaphor, but it is alive and well in text encodings too.  I'll talk about projects (mine and others') that explore neural spaces in poetic and game-like ways. Focusing on text play in this talk, we'll visit media collages, mistaken translations, cross-modal cutups, and the dusty bottoms of game databases in search of the uncanny glitch that make us laugh because it's true.
  #     - time: 10:00&nbsp;&ndash;&nbsp;10:30
  #       title: "Break"
  #     - time: 10:30&nbsp;&ndash;&nbsp;11:15
  #       title: "Knowledge Intensive Reinforcement Learning \n **Tim Rocktäschel** [[link]](https://www.youtube.com/watch?v=XIQgB_MerAw&t=5097)"
  #       abstract: >+
  #         Progress in Reinforcement Learning (RL) methods goes hand-in-hand with the development of challenging environments that test the limits of current approaches. While existing RL environments are either sufficiently complex or based on fast simulation, they are rarely both these things. Moreover, research in RL has predominantly focused on environments that can be approached tabula rasa, i.e., without agents requiring transfer of any domain or world knowledge outside of the simulated environment. I will talk about the NetHack Learning Environment (NLE), a scalable, procedurally generated, stochastic, rich, and challenging environment for research based on the popular single-player terminal-based rogue-like game, NetHack. We argue that NetHack is sufficiently complex to drive long-term research on problems such as exploration, planning, skill acquisition, and language-conditioned RL, while dramatically reducing the computational resources required to gather a large amount of experience. Interestingly, this game is extremely challenging even for human players who often need many years to solve it the first time and who generally consult external natural language knowledge sources like the NetHack Wiki to improve their skills. I will cover some of our recent work on utilizing language information in this challenging environment.
  #     - time: 11:15&nbsp;&ndash;&nbsp;12:00
  #       title: "Training Agents to Learn to Ask for Help in Virtual Environments \n **Hal Daumé III** [[link]](https://www.youtube.com/watch?v=XIQgB_MerAw&t=8456)"
  #       abstract: >+
  #         "Agent" has largely become synonymous with "autonomous agent", but I'll argue that scoping our study of agents to those that are fully autonomous is a mistake: instead, we should aim to train agents that can assist humans, and be assisted by humans. In line with this goal, I will describe recent and ongoing work in the space of assisted agent navigation, where agents can ask humans for help, and where they can describe their own behaviors. This talk will largely be based on joint work with Sudha Rao, Khanh Nguyen, Lingjun Zhao, and Yonatan Bisk.
  #     - time: 12:00&nbsp;&ndash;&nbsp;13:30
  #       title: "Lunch Break"
  #     - time: 13:30&nbsp;&ndash;&nbsp;14:15
  #       title: "Controllable Text Generation for Interactive Virtual Environments \n **Shrimai Prabhumoye** [[link]](https://youtu.be/XIQgB_MerAw?t=16409)"
  #       abstract: >+
  #         Since the dawn of the digital age, interactive virtual environments and electronic games have played a huge role in shaping our lives. Not only are they a source of entertainment but they also teach us important life skills such as strategic planning, collaboration, and problem solving. Therefore, online gamers expect their virtual environment to be aware of their situation (e.g., position in a game) and interact with them in natural language. In this talk, I describe novel techniques to generate text in a particular style. This talk provides an approach of generating engaging naturalistic conversation responses using knowledge generated by pre-trained language models, considering their recent success in a multitude of NLP tasks. The talk will conclude with exploring whether pretrained language models can be situated in these virtual spaces and generate dialogue in a zero-shot manner.
  #     - time: 14:15&nbsp;&ndash;&nbsp;15:00
  #       title: "ScienceWorld: Is your Agent Smarter than a 5th Grader? \n **Peter Jansen** [[link]](https://www.youtube.com/watch?v=XIQgB_MerAw&t=18727)"
  #       abstract: >+
  #         Question answering models have rapidly increased their ability to answer natural language questions in recent years, due in large part to large pre-trained neural network models called Language Models.  These language models have felled many benchmarks, including recently achieving an "A" grade on answering standardized multiple choice elementary science exams.  But how much do these language models truly know about elementary science, and how robust is their knowledge?  In this work, we present ScienceWorld, a new benchmark to test agents' scientific reasoning abilities.  ScienceWorld is an interactive text game environment that tasks agents with performing 30 tasks drawn from the elementary science curriculum, like melting ice, building simple electrical circuits, using pollinators to help grow fruits, or understanding dominant versus recessive genetic traits.  We show that current state-of-the-art language models that can easily answer elementary science questions, such as whether a metal fork is conductive or not, struggle when tasked to conduct an experiment to test this in a grounded, interactive environment, even with substantial training data.  This presents the question of whether current models are simply retrieving answers to questions by way of observing a large number of similar input examples, or if they have learned to reason about concepts in a reusable manner.  We hypothesize that agents need to be grounded in interactive environments to achieve such reasoning abilities.  Our experiments provide empirical evidence supporting this hypothesis -- showing that a 1.5 million parameter agent trained interactively for 100k steps outperforms an 11 billion parameter model statically trained for scientific question answering and reasoning via millions of expert demonstrations.
  #     - time: 15:00&nbsp;&ndash;&nbsp;15:05
  #       title: "Closing Remarks"
  #     - time: 15:05&nbsp;&ndash;&nbsp;15:30
  #       title: "Break"
  #     - time: 15:30&nbsp;&ndash;&nbsp;16:30
  #       title: "Virtual Poster Session on GatherTown - All posters"
  #     - time: <b>Friday July 15<sup>th</sup></b> 15:30&nbsp;&ndash;&nbsp;16:30
  #       title: "Joint In-person Poster Session with Narrative Understanding workshop - Regency ballroom on the 7<sup>th</sup> floor"

  # - type: invited_speakers.html
  #   section_id: invited_speakers
  #   title: Speakers
  #   background_style: bg-dark text-white
  #   members:
  #     - title: Shrimai Prabhumoye
  #       text: Nvidia
  #       image: assets/img/invited_speakers/shrimai.jpg
  #       url: https://www.cs.cmu.edu/~sprabhum/
  #     - title: Tim Rocktäschel
  #       text: University College London & Deepmind
  #       image: assets/img/invited_speakers/tim.jpg
  #       url: https://rockt.github.io/
  #     - title: Hal Daumé III
  #       text: University of Maryland & Microsoft Research
  #       image: assets/img/invited_speakers/hal.png
  #       url: http://hal3.name/
  #     - title: Peter Jansen
  #       text: University of Arizona
  #       image: assets/img/invited_speakers/peter.jpg
  #       url: http://cognitiveai.org/
  #     - title: Lynn Cherny
  #       text: GhostWeather
  #       image: assets/img/invited_speakers/lynn.jpg
  #       url: http://www.ghostweather.com/

  # - type: paragraphs.html
  #   section_id: accepted_papers
  #   title: Accepted Papers
  #   background_style: bg-lightdark
  #   texts:
  #     - >+
  #       ### Long Papers
  #         * [A Systematic Survey of Text Worlds as Embodied Natural Language Environments](https://wordplay-workshop.github.io/modern/assets/pdfs/3.pdf)
  #         * [Dungeons and Dragons as a Dialogue Challenge for Artificial Intelligence](https://wordplay-workshop.github.io/modern/assets/pdfs/4.pdf)
  #         * [A Minimal Computational Improviser Based on Oral Thought](https://wordplay-workshop.github.io/modern/assets/pdfs/5.pdf)
  #         * [Craft an Iron Sword: Dynamically Generating Interactive Game Characters by Prompting Large Language Models Tuned on Code](https://wordplay-workshop.github.io/modern/assets/pdfs/6.pdf)
  #         * [A Sequence Modelling Approach to Question Answering in Text-Based Games](https://wordplay-workshop.github.io/modern/assets/pdfs/8.pdf)
  #         * [Instruction Following in Text-Based Games](https://wordplay-workshop.github.io/modern/assets/pdfs/9.pdf)
  #         * [Using Language Models to Convert Between Natural Language and Game Commands](https://wordplay-workshop.github.io/modern/assets/pdfs/10.pdf)
  #         * [Modeling Perspective-Dependent Ambiguity in Collaborative Dialogue](https://wordplay-workshop.github.io/modern/assets/pdfs/12.pdf)
  #     - >+
  #       ### Short Papers
  #         * [Towards Knowledge-Graph Constrained Generation for Text Adventure Games](https://wordplay-workshop.github.io/modern/assets/pdfs/7.pdf)
  #         * [Learning Neuro-Symbolic World Models for Text-Based Game Playing Agents](https://wordplay-workshop.github.io/modern/assets/pdfs/14.pdf)
  #     - >+
  #       ### Extended Abstracts
  #         * [Automatic Exploration of Textual Environments with Language-Conditioned Autotelic Agents](https://wordplay-workshop.github.io/modern/assets/pdfs/11.pdf)
  #         * [Challenges in Explainability and Knowledge Extraction](https://wordplay-workshop.github.io/modern/assets/pdfs/13.pdf)


  - type: organizers.html
    section_id: organizers
    title: Organizers
    background_style: bg-dark text-white
    members:
      - title: Prithviraj Ammanabrolu
        text: Allen Institute for AI
        image: assets/img/organizers/raj.jpg
        url: http://prithvirajva.com
      - title: Marc-Alexandre Côté
        text: Microsoft Research
        image: assets/img/organizers/marc.jpg
        url: https://www.microsoft.com/en-us/research/people/macote/
      - title: Belinda Zou Li
        text: Massachusetts Institute of Technology
        image: assets/img/organizers/belinda.jpg
        url: https://belindal.github.io
      - title: Lara Martin
        text: University of Pennsylvania
        image: assets/img/organizers/lara.jpeg
        url: https://laramartin.net/
      - title: Nanyun (Violet) Peng
        text: UCLA
        image: assets/img/organizers/violet.jpg
        url: https://vnpeng.net/
      - title: Alane Suhr
        text: Allen Institute for AI, UC Berkeley
        image: assets/img/organizers/alane.jpg
        url: https://www.alanesuhr.com/
      - title: Ronen Tamari
        text: The Hebrew University of Jerusalem, Israel
        image: assets/img/organizers/ronen.jpeg
        url: https://ronentk.github.io/
      - title: Laetitia Teodorescu
        text: Inria, France
        image: assets/img/organizers/laetitia.jpg
        url: https://place.holder
      - title: Adam Trischler
        text: Microsoft Research
        image: assets/img/organizers/adam.jpg
        url: https://www.microsoft.com/en-us/research/people/adtrisch/
      - title: Jason Weston
        text: Meta AI Research
        image: assets/img/organizers/jason.jpg
        url: https://www.thespermwhale.com/jaseweston/
      - title: Xingdi Yuan
        text: Microsoft Research
        image: assets/img/organizers/eric.jpg
        url: https://xingdi-eric-yuan.github.io/

---
