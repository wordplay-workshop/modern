---
layout: home
header:
  title: "Wordplay: When Language Meets Games
          @ NAACL 2022"
  text: >
    Your one stop shop for all things interactive narrative + AI!

  action: # action button is optional
    label: Back to the '80s
    url: https://wordplay-workshop.github.io/


sections:
  - type: paragraph.html
    section_id: overview
    title: Overview
    text: >+

      **Date and time**: Full day workshop on July 14<sup>th</sup> <br />

      **Location**: "Room 501 - Chiwawa (Virtual link: TBD). <br />"

      This workshop will focus on exploring the utility of interactive narratives, think everything from classic text-adventures like [Zork](http://textadventures.online/play/?story=http%3A%2F%2Fwww.ifarchive.org%2Fif-archive%2Fgames%2Fhugo%2Fhugozork.hex) to modern [Twine](https://twinery.org/) games, to fill a role as the learning environments of choice for language-based tasks including but not limited to storytelling. A few previous iterations of this workshop took place very successfully with hundreds of attendees, at NeurIPS 2018 and NeurIPS 2020. Since then, the community of people working in this area has rapidly increased. This workshop aims to be a centralized place where all researchers involved across a breadth of fields can interact and learn from each other. Furthermore, it will act as a showcase to the wider NLP/RL/Game communities on interactive narrative's place as a learning environment. The program will feature a collection of invited talks in addition to contributed talks and posters from each of these sections of the interactive narrative community and the wider NLP and RL communities.  <br />

      We like all things:

      * Interactive narrative: game playing RL agents, game generation, etc.

      * Interactive language learning

      * Natural language generation

      * Improvisational storytelling

      * And more! Anything you can think of that involves narrative, interactivity, and language!

      <br />

      [Check out the full version of our overview!](/modern/full_overview)

  # - type: paragraph.html
  #   section_id: cfp
  #   title: Call For Papers
  #   background_style: bg-lightdark
  #   text: >+

  #     **Submission website:** [OpenReview](https://openreview.net/group?id=aclweb.org/NAACL/2022/Workshop/Wordplay).

  #     **Submission deadline:** ~~15<sup>th</sup> May 2022 (23:59 AoE)~~ 31<sup>st</sup> May 2022 (23:59 AoE)

  #     **Author notification:** 18<sup>th</sup> June 2022 (23:59 AoE) <br/>

  #     We welcome original research papers ranging between **4-8** pages in length (not including references or supplementary materials), formatted according to [the NAACL 2022 style](https://github.com/acl-org/acl-style-files). Submissions should be in **.pdf** format. Since the review process is **double-blind**, all papers should be appropriately anonymised. Authors have the option of including supplementary manuscript containing further details of their work into **the same .pdf file**, it is entirely up to the reviewers to decide whether they wish to consult this additional material. Authors are strongly encouraged to make data and code publicly available whenever possible. The accepted papers will be posted on the workshop website and will not appear in the NAACL proceedings.<br/>

  #     We also welcome papers that have been previously reviewed at the ACL Rolling Review system. Authors can use the commitment submission to share the link to their paper's ARR reviews. <br/>

  #     In addition, we welcome extended abstracts of up to 2 pages that describe open problems and challenges in this area.
  #     The papers will be non-archival, we welcome papers that have been published or submitted to other places.
  #     However, authors are required to acknowledge their papers' original appearance in such cases. <br/>

  #     All accepted papers and extended abstracts will be presented as posters.
  #     The program committee will select a few papers for oral presentation.

  - type: schedule.html
    section_id: schedule
    title: Schedule - tentative (Pacific Time)
    background_style: bg-lightdark
    events:
      - time: 08:30&nbsp;&ndash;&nbsp;08:40
        title: "Opening Remarks"
      - time: 08:40&nbsp;&ndash;&nbsp;09:25
        title: "Keynote 1 - Text Toys and Glitch Poetics - Lynn Cherny"
      - time: 09:25&nbsp;&ndash;&nbsp;10:00
        title: "Poster Session 1"
      - time: 10:00&nbsp;&ndash;&nbsp;10:30
        title: "Break"
      - time: 10:30&nbsp;&ndash;&nbsp;11:15
        title: "Keynote 2 - Knowledge Intensive Reinforcement Learning - Tim Rocktäschel"
      - time: 11:15&nbsp;&ndash;&nbsp;12:00
        title: "Keynote 3 - Training Agents to Learn to Ask for Help in Virtual Environments - Hal Daumé III"
      - time: 12:00&nbsp;&ndash;&nbsp;13:30
        title: "Lunch Break"
      - time: 13:30&nbsp;&ndash;&nbsp;14:15
        title: "Keynote 4 - Controllable Text Generation for Interactive Virtual Environments - Shrimai Prabhumoye"
      - time: 14:15&nbsp;&ndash;&nbsp;15:00
        title: "Keynote 5 - ScienceWorld: Is your Agent Smarter than a 5th Grader? - Peter Jansen"
      - time: 15:00&nbsp;&ndash;&nbsp;15:05
        title: "Closing Remarks"
      - time: 15:05&nbsp;&ndash;&nbsp;15:30
        title: "Break"
      - time: 15:30&nbsp;&ndash;&nbsp;16:00
        title: "Poster Session 2"

  - type: invited_speakers.html
    section_id: invited_speakers
    title: Speakers
    background_style: bg-dark text-white
    members:
      - title: Shrimai Prabhumoye
        text: Nvidia
        image: assets/img/invited_speakers/shrimai.jpg
        url: https://www.cs.cmu.edu/~sprabhum/
      - title: Tim Rocktäschel
        text: University College London & Meta AI Research
        image: assets/img/invited_speakers/tim.jpg
        url: https://rockt.github.io/
      - title: Hal Daumé III
        text: University of Maryland & Microsoft Research
        image: assets/img/invited_speakers/hal.png
        url: http://hal3.name/
      - title: Peter Jansen
        text: University of Arizona
        image: assets/img/invited_speakers/peter.jpg
        url: http://cognitiveai.org/
      - title: Lynn Cherny
        text: GhostWeather
        image: assets/img/invited_speakers/lynn.jpg
        url: http://www.ghostweather.com/

  - type: paragraphs.html
    section_id: accepted_papers
    title: Accepted Papers
    background_style: bg-lightdark
    texts:
      - >+
        ### Long Papers
          * [A Systematic Survey of Text Worlds as Embodied Natural Language Environments](https://wordplay-workshop.github.io/modern/pdfs/3.pdf)
          * [Dungeons and Dragons as a Dialogue Challenge for Artificial Intelligence](https://wordplay-workshop.github.io/modern/pdfs/4.pdf)
          * [A Minimal Computational Improviser Based on Oral Thought](https://wordplay-workshop.github.io/modern/pdfs/5.pdf)
          * [Craft an Iron Sword: Dynamically Generating Interactive Game Characters by Prompting Large Language Models Tuned on Code](https://wordplay-workshop.github.io/modern/pdfs/6.pdf)
          * [A Sequence Modelling Approach to Question Answering in Text-Based Games](https://wordplay-workshop.github.io/modern/pdfs/8.pdf)
          * [Instruction Following in Text-Based Games](https://wordplay-workshop.github.io/modern/pdfs/9.pdf)
          * [Using Language Models to Convert Between Natural Language and Game Commands](https://wordplay-workshop.github.io/modern/pdfs/10.pdf)
          * [Modeling Perspective-Dependent Ambiguity in Collaborative Dialogue](https://wordplay-workshop.github.io/modern/pdfs/12.pdf)
      - >+
        ### Short Papers
          * [Towards Knowledge-Graph Constrained Generation for Text Adventure Games](https://wordplay-workshop.github.io/modern/pdfs/7.pdf)
          * [Learning Neuro-Symbolic World Models for Text-Based Game Playing Agents](https://wordplay-workshop.github.io/modern/pdfs/14.pdf)
      - >+
        ### Extended Abstracts
          * [Automatic Exploration of Textual Environments with Language-Conditioned Autotelic Agents](https://wordplay-workshop.github.io/modern/pdfs/11.pdf)
          * [Challenges in Explainability and Knowledge Extraction](https://wordplay-workshop.github.io/modern/pdfs/13.pdf)

  - type: organizers.html
    section_id: organizers
    title: Organizers
    background_style: bg-dark text-white
    members:
      - title: Prithviraj Ammanabrolu
        text: Allen Institute for AI
        image: assets/img/organizers/raj.jpg
        url: http://prithvirajva.com
      - title: Xingdi Yuan
        text: Microsoft Research
        image: assets/img/organizers/eric.jpg
        url: https://xingdi-eric-yuan.github.io/
      - title: Marc-Alexandre Côté
        text: Microsoft Research
        image: assets/img/organizers/marc.jpg
        url: https://www.microsoft.com/en-us/research/people/macote/
      - title: Ashutosh Adhikari
        text: Microsoft Turing
        image: assets/img/organizers/ash.jpg
        url: https://ashutosh-adhikari.github.io/
      - title: Matthew Hausknecht
        text: Argo AI
        image: assets/img/organizers/matthew.png
        url: https://mhauskn.github.io/
      - title: Kory Mathewson
        text: DeepMind
        image: assets/img/organizers/kory.jpg
        url: https://korymathewson.com/
      - title: Michiaki Tatsubori
        text: IBM Research
        image: assets/img/organizers/michiaki.jpg
        url: https://researcher.watson.ibm.com/researcher/view.php?person=jp-MICH
      - title: Jack Urbanek
        text: Meta AI Research
        image: assets/img/organizers/jack.jpg
        url: https://ai.facebook.com/people/jack-urbanek/
      - title: Adam Trischler
        text: Microsoft Research
        image: assets/img/organizers/adam.jpg
        url: https://www.microsoft.com/en-us/research/people/adtrisch/
      - title: Jason Weston
        text: Meta AI Research
        image: assets/img/organizers/jason.jpg
        url: https://www.thespermwhale.com/jaseweston/

  - type: paragraph.html
    section_id: reviewers
    title: Reviewers
    background_style:
    text: >+
      * The organizers would like to thank [Guiliang Liu](http://guiliang.me/) and [Raghuram Mandyam Annasamy](https://www.linkedin.com/in/maraghuram/) for helping us in the reviewing process.

---
